{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AiswaryaGoriparthi/Aiswarya_INFO5731_Fall2024/blob/main/Goriparthi_Aiswarya_Assignment_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryk8D1Q4Wsrp"
      },
      "source": [
        "# **INFO5731 Assignment 2**\n",
        "\n",
        "In this assignment, you will work on gathering text data from an open data source via web scraping or API. Following this, you will need to clean the text data and perform syntactic analysis on the data. Follow the instructions carefully and design well-structured Python programs to address each question.\n",
        "\n",
        "**Expectations**:\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "* **Make sure to submit the cleaned data CSV in the comment section - 10 points**\n",
        "\n",
        "**Total points**: 100\n",
        "\n",
        "**Deadline**: Tuesday, at 11:59 PM.\n",
        "\n",
        "**Late Submission will have a penalty of 10% reduction for each day after the deadline.**\n",
        "\n",
        "**Please check that the link you submitted can be opened and points to the correct assignment.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkzR8cFAyGik"
      },
      "source": [
        "# Question 1 (40 points)\n",
        "\n",
        "Write a python program to collect text data from **either of the following sources** and save the data into a **csv file:**\n",
        "\n",
        "(1) Collect all the customer reviews of a product (you can choose any porduct) on amazon. [atleast 1000 reviews]\n",
        "\n",
        "(2) Collect the top 1000 User Reviews of a movie recently in 2023 or 2024 (you can choose any movie) from IMDB. [If one movie doesn't have sufficient reviews, collect reviews of atleast 2 or 3 movies]\n",
        "\n",
        "(3) Collect all the reviews of the top 1000 most popular software from G2 or Capterra.\n",
        "\n",
        "(4) Collect the **abstracts** of the top 10000 research papers by using the query \"machine learning\", \"data science\", \"artifical intelligence\", or \"information extraction\" from Semantic Scholar.\n",
        "\n",
        "(5) Collect all the information of the 904 narrators in the Densho Digital Repository.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4 pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw2cN6et8PXM",
        "outputId": "657155d2-85d4-47a0-9974-33aa5eae3e7d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jDyTKYs-yGit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02545eb8-d5dc-4616-9cb0-611f321fb384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching page: https://www.imdb.com/title/tt0439572/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0439572/reviews?ref_=tt_ql_3&page=2\n",
            "No more reviews found for tt0439572 on page 2.\n",
            "Fetching page: https://www.imdb.com/title/tt8178634/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt8178634/reviews?ref_=tt_ql_3&page=2\n",
            "No more reviews found for tt8178634 on page 2.\n",
            "Fetching page: https://www.imdb.com/title/tt0111161/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt0111161 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt9389998/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt9389998 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0068646/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt0068646 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0468569/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0468569/reviews?ref_=tt_ql_3&page=2\n",
            "No more reviews found for tt0468569 on page 2.\n",
            "Fetching page: https://www.imdb.com/title/tt5074352/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt5074352 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt15330776/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt15330776 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt2561572/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt2561572/reviews?ref_=tt_ql_3&page=2\n",
            "Fetched 25 reviews from page 2. Total reviews collected: 50\n",
            "Fetching page: https://www.imdb.com/title/tt2561572/reviews?ref_=tt_ql_3&page=3\n",
            "Fetched 25 reviews from page 3. Total reviews collected: 75\n",
            "Fetching page: https://www.imdb.com/title/tt2561572/reviews?ref_=tt_ql_3&page=4\n",
            "Fetched 25 reviews from page 4. Total reviews collected: 100\n",
            "Fetching page: https://www.imdb.com/title/tt2561572/reviews?ref_=tt_ql_3&page=5\n",
            "Fetched 25 reviews from page 5. Total reviews collected: 125\n",
            "Fetching page: https://www.imdb.com/title/tt2561572/reviews?ref_=tt_ql_3&page=6\n",
            "Fetched 25 reviews from page 6. Total reviews collected: 150\n",
            "Fetching page: https://www.imdb.com/title/tt2561572/reviews?ref_=tt_ql_3&page=7\n",
            "Fetched 25 reviews from page 7. Total reviews collected: 175\n",
            "Fetching page: https://www.imdb.com/title/tt2561572/reviews?ref_=tt_ql_3&page=8\n",
            "Fetched 25 reviews from page 8. Total reviews collected: 200\n",
            "Fetching page: https://www.imdb.com/title/tt2561572/reviews?ref_=tt_ql_3&page=9\n",
            "Fetched 25 reviews from page 9. Total reviews collected: 225\n",
            "Fetching page: https://www.imdb.com/title/tt2561572/reviews?ref_=tt_ql_3&page=10\n",
            "No more reviews found for tt2561572 on page 10.\n",
            "Fetching page: https://www.imdb.com/title/tt1189073/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt1189073/reviews?ref_=tt_ql_3&page=2\n",
            "Fetched 25 reviews from page 2. Total reviews collected: 50\n",
            "Fetching page: https://www.imdb.com/title/tt1189073/reviews?ref_=tt_ql_3&page=3\n",
            "Fetched 25 reviews from page 3. Total reviews collected: 75\n",
            "Fetching page: https://www.imdb.com/title/tt1189073/reviews?ref_=tt_ql_3&page=4\n",
            "Fetched 25 reviews from page 4. Total reviews collected: 100\n",
            "Fetching page: https://www.imdb.com/title/tt1189073/reviews?ref_=tt_ql_3&page=5\n",
            "No more reviews found for tt1189073 on page 5.\n",
            "Fetching page: https://www.imdb.com/title/tt0111161/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0111161/reviews?ref_=tt_ql_3&page=2\n",
            "Fetched 25 reviews from page 2. Total reviews collected: 50\n",
            "Fetching page: https://www.imdb.com/title/tt0111161/reviews?ref_=tt_ql_3&page=3\n",
            "No more reviews found for tt0111161 on page 3.\n",
            "Fetching page: https://www.imdb.com/title/tt0068646/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt0068646 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0108052/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0108052/reviews?ref_=tt_ql_3&page=2\n",
            "Fetched 25 reviews from page 2. Total reviews collected: 50\n",
            "Fetching page: https://www.imdb.com/title/tt0108052/reviews?ref_=tt_ql_3&page=3\n",
            "No more reviews found for tt0108052 on page 3.\n",
            "Fetching page: https://www.imdb.com/title/tt0468569/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt0468569 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0110912/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt0110912 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0109830/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0109830/reviews?ref_=tt_ql_3&page=2\n",
            "Fetched 25 reviews from page 2. Total reviews collected: 50\n",
            "Fetching page: https://www.imdb.com/title/tt0109830/reviews?ref_=tt_ql_3&page=3\n",
            "No more reviews found for tt0109830 on page 3.\n",
            "Fetching page: https://www.imdb.com/title/tt1375666/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt1375666 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0137523/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt0137523 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0133093/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0133093/reviews?ref_=tt_ql_3&page=2\n",
            "No more reviews found for tt0133093 on page 2.\n",
            "Fetching page: https://www.imdb.com/title/tt0167260/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0167260/reviews?ref_=tt_ql_3&page=2\n",
            "No more reviews found for tt0167260 on page 2.\n",
            "Fetching page: https://www.imdb.com/title/tt0111161/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0111161/reviews?ref_=tt_ql_3&page=2\n",
            "No more reviews found for tt0111161 on page 2.\n",
            "Fetching page: https://www.imdb.com/title/tt0068646/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0068646/reviews?ref_=tt_ql_3&page=2\n",
            "No more reviews found for tt0068646 on page 2.\n",
            "Fetching page: https://www.imdb.com/title/tt6751668/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt6751668 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0050083/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0050083/reviews?ref_=tt_ql_3&page=2\n",
            "Fetched 25 reviews from page 2. Total reviews collected: 50\n",
            "Fetching page: https://www.imdb.com/title/tt0050083/reviews?ref_=tt_ql_3&page=3\n",
            "Fetched 25 reviews from page 3. Total reviews collected: 75\n",
            "Fetching page: https://www.imdb.com/title/tt0050083/reviews?ref_=tt_ql_3&page=4\n",
            "No more reviews found for tt0050083 on page 4.\n",
            "Fetching page: https://www.imdb.com/title/tt0108052/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0108052/reviews?ref_=tt_ql_3&page=2\n",
            "No more reviews found for tt0108052 on page 2.\n",
            "Fetching page: https://www.imdb.com/title/tt0167260/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt0167260 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0110912/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt0110912 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0060196/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 23 reviews from page 1. Total reviews collected: 23\n",
            "Fetching page: https://www.imdb.com/title/tt0060196/reviews?ref_=tt_ql_3&page=2\n",
            "No more reviews found for tt0060196 on page 2.\n",
            "Fetching page: https://www.imdb.com/title/tt0120737/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt0120737 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0137523/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt0137523 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0109830/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0109830/reviews?ref_=tt_ql_3&page=2\n",
            "No more reviews found for tt0109830 on page 2.\n",
            "Fetching page: https://www.imdb.com/title/tt0080684/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt0080684 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0167261/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0167261/reviews?ref_=tt_ql_3&page=2\n",
            "No more reviews found for tt0167261 on page 2.\n",
            "Fetching page: https://www.imdb.com/title/tt0133093/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0133093/reviews?ref_=tt_ql_3&page=2\n",
            "No more reviews found for tt0133093 on page 2.\n",
            "Fetching page: https://www.imdb.com/title/tt0099685/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0099685/reviews?ref_=tt_ql_3&page=2\n",
            "No more reviews found for tt0099685 on page 2.\n",
            "Fetching page: https://www.imdb.com/title/tt0073486/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt0073486 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt8503618/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt8503618/reviews?ref_=tt_ql_3&page=2\n",
            "Fetched 25 reviews from page 2. Total reviews collected: 50\n",
            "Fetching page: https://www.imdb.com/title/tt8503618/reviews?ref_=tt_ql_3&page=3\n",
            "Fetched 25 reviews from page 3. Total reviews collected: 75\n",
            "Fetching page: https://www.imdb.com/title/tt8503618/reviews?ref_=tt_ql_3&page=4\n",
            "No more reviews found for tt8503618 on page 4.\n",
            "Fetching page: https://www.imdb.com/title/tt0047478/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0047478/reviews?ref_=tt_ql_3&page=2\n",
            "Fetched 25 reviews from page 2. Total reviews collected: 50\n",
            "Fetching page: https://www.imdb.com/title/tt0047478/reviews?ref_=tt_ql_3&page=3\n",
            "Fetched 25 reviews from page 3. Total reviews collected: 75\n",
            "Fetching page: https://www.imdb.com/title/tt0047478/reviews?ref_=tt_ql_3&page=4\n",
            "Fetched 25 reviews from page 4. Total reviews collected: 100\n",
            "Fetching page: https://www.imdb.com/title/tt0047478/reviews?ref_=tt_ql_3&page=5\n",
            "Fetched 25 reviews from page 5. Total reviews collected: 125\n",
            "Fetching page: https://www.imdb.com/title/tt0047478/reviews?ref_=tt_ql_3&page=6\n",
            "Fetched 25 reviews from page 6. Total reviews collected: 150\n",
            "Fetching page: https://www.imdb.com/title/tt0047478/reviews?ref_=tt_ql_3&page=7\n",
            "Fetched 25 reviews from page 7. Total reviews collected: 175\n",
            "Fetching page: https://www.imdb.com/title/tt0047478/reviews?ref_=tt_ql_3&page=8\n",
            "Fetched 25 reviews from page 8. Total reviews collected: 200\n",
            "Fetching page: https://www.imdb.com/title/tt0047478/reviews?ref_=tt_ql_3&page=9\n",
            "Fetched 25 reviews from page 9. Total reviews collected: 225\n",
            "Fetching page: https://www.imdb.com/title/tt0047478/reviews?ref_=tt_ql_3&page=10\n",
            "No more reviews found for tt0047478 on page 10.\n",
            "Fetching page: https://www.imdb.com/title/tt0114369/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt0114369 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0317248/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 24 reviews from page 1. Total reviews collected: 24\n",
            "Fetching page: https://www.imdb.com/title/tt0317248/reviews?ref_=tt_ql_3&page=2\n",
            "No more reviews found for tt0317248 on page 2.\n",
            "Fetching page: https://www.imdb.com/title/tt0816692/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt0816692 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0245429/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0245429/reviews?ref_=tt_ql_3&page=2\n",
            "No more reviews found for tt0245429 on page 2.\n",
            "Fetching page: https://www.imdb.com/title/tt0114814/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt0114814 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0120815/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt0120815 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0120689/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt0120689 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0110413/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0110413/reviews?ref_=tt_ql_3&page=2\n",
            "No more reviews found for tt0110413 on page 2.\n",
            "Fetching page: https://www.imdb.com/title/tt0110357/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0110357/reviews?ref_=tt_ql_3&page=2\n",
            "No more reviews found for tt0110357 on page 2.\n",
            "Fetching page: https://www.imdb.com/title/tt0172495/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0172495/reviews?ref_=tt_ql_3&page=2\n",
            "Fetched 25 reviews from page 2. Total reviews collected: 50\n",
            "Fetching page: https://www.imdb.com/title/tt0172495/reviews?ref_=tt_ql_3&page=3\n",
            "Fetched 25 reviews from page 3. Total reviews collected: 75\n",
            "Fetching page: https://www.imdb.com/title/tt0172495/reviews?ref_=tt_ql_3&page=4\n",
            "Fetched 25 reviews from page 4. Total reviews collected: 100\n",
            "Fetching page: https://www.imdb.com/title/tt0172495/reviews?ref_=tt_ql_3&page=5\n",
            "No more reviews found for tt0172495 on page 5.\n",
            "Fetching page: https://www.imdb.com/title/tt0102926/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0102926/reviews?ref_=tt_ql_3&page=2\n",
            "No more reviews found for tt0102926 on page 2.\n",
            "Fetching page: https://www.imdb.com/title/tt0038650/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt0038650 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0253474/reviews?ref_=tt_ql_3&page=1\n",
            "No more reviews found for tt0253474 on page 1.\n",
            "Fetching page: https://www.imdb.com/title/tt0120586/reviews?ref_=tt_ql_3&page=1\n",
            "Fetched 25 reviews from page 1. Total reviews collected: 25\n",
            "Fetching page: https://www.imdb.com/title/tt0120586/reviews?ref_=tt_ql_3&page=2\n",
            "Fetched 25 reviews from page 2. Total reviews collected: 50\n",
            "Fetching page: https://www.imdb.com/title/tt0120586/reviews?ref_=tt_ql_3&page=3\n",
            "No more reviews found for tt0120586 on page 3.\n",
            "Saved 1447 reviews to imdb_reviews.csv\n"
          ]
        }
      ],
      "source": [
        "#your code here\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def fetch_reviews(movie_id):\n",
        "    reviews = []\n",
        "    page = 1\n",
        "\n",
        "    while True:\n",
        "        # Construct the URL for the reviews page\n",
        "        url = f\"https://www.imdb.com/title/{movie_id}/reviews?ref_=tt_ql_3&page={page}\"\n",
        "        print(f\"Fetching page: {url}\")\n",
        "\n",
        "        # Set headers to mimic a browser\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36'\n",
        "        }\n",
        "\n",
        "        response = requests.get(url, headers=headers)\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Failed to retrieve page {page}. HTTP Status Code: {response.status_code}\")\n",
        "            break\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        review_elements = soup.find_all('div', class_='review-container')\n",
        "\n",
        "        if not review_elements:\n",
        "            print(f\"No more reviews found for {movie_id} on page {page}.\")\n",
        "            break\n",
        "\n",
        "        # Extract reviews from the page\n",
        "        for review in review_elements:\n",
        "            title = review.find('a', class_='title').text.strip()\n",
        "            content = review.find('div', class_='text').text.strip()\n",
        "            reviews.append({'Title': title, 'Content': content})\n",
        "\n",
        "        print(f\"Fetched {len(review_elements)} reviews from page {page}. Total reviews collected: {len(reviews)}\")\n",
        "        page += 1\n",
        "\n",
        "    return reviews\n",
        "\n",
        "# List of movie IDs to scrape\n",
        "movie_ids = [\"tt0439572\", \"tt8178634\",\"tt0111161\",\"tt9389998\",\n",
        "             \"tt0068646\", \"tt0468569\", \"tt5074352\", \"tt15330776\",\n",
        "             \"tt2561572\", \"tt1189073\",\"tt0111161\",\"tt0068646\", \"tt0108052\", \"tt0468569\",\"tt0110912\",\n",
        "             \"tt0109830\", \"tt1375666\",\"tt0137523\",\"tt0133093\",\"tt0167260\", \"tt0111161\", \"tt0068646\",\n",
        "             \"tt6751668\", \"tt0050083\", \"tt0108052\", \"tt0167260\", \"tt0110912\",\"tt0060196\", \"tt0120737\", \"tt0137523\", \"tt0109830\", \"tt0080684\", \"tt0167261\",\n",
        "             \"tt0133093\",\"tt0099685\", \"tt0073486\", \"tt8503618\", \"tt0047478\", \"tt0114369\", \"tt0317248\", \"tt0816692\", \"tt0245429\",\n",
        "             \"tt0114814\", \"tt0120815\", \"tt0120689\", \"tt0110413\", \"tt0110357\",\"tt0172495\",\"tt0102926\",\"tt0038650\", \"tt0253474\",\"tt0120586\"]  # Example movie IDs\n",
        "all_reviews = []\n",
        "\n",
        "for movie_id in movie_ids:\n",
        "    all_reviews.extend(fetch_reviews(movie_id))\n",
        "\n",
        "# Save to CSV\n",
        "df = pd.DataFrame(all_reviews)\n",
        "df.to_csv('imdb_reviews.csv', index=False)\n",
        "print(f\"Saved {len(all_reviews)} reviews to imdb_reviews.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90_NR8c5XGWc"
      },
      "source": [
        "# Question 2 (30 points)\n",
        "\n",
        "Write a python program to **clean the text data** you collected in the previous question and save the clean data in a new column in the csv file. The data cleaning steps include: [Code and output is required for each part]\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "\n",
        "(3) Remove stopwords by using the stopwords list.\n",
        "\n",
        "(4) Lowercase all texts\n",
        "\n",
        "(5) Stemming.\n",
        "\n",
        "(6) Lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5QX6bJjGWXY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9888435b-473b-42e9-b439-2d1b13230a5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned data saved to 'imdb_reviews_cleaned.csv'.\n"
          ]
        }
      ],
      "source": [
        "# Write code for each of the sub parts with proper comments.\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('imdb_reviews.csv')\n",
        "\n",
        "# (1) Remove special characters and punctuations\n",
        "def remove_special_characters(text):\n",
        "    return re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "\n",
        "# (2) Remove numbers\n",
        "def remove_numbers(text):\n",
        "    return re.sub(r'\\d+', '', text)\n",
        "\n",
        "# (3) Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def remove_stopwords(text):\n",
        "    words = text.split()\n",
        "    return ' '.join([word for word in words if word.lower() not in stop_words])\n",
        "\n",
        "# (4) Convert to lowercase\n",
        "def convert_to_lowercase(text):\n",
        "    return text.lower()\n",
        "\n",
        "# (5) Stemming\n",
        "ps = PorterStemmer()\n",
        "def apply_stemming(text):\n",
        "    words = text.split()\n",
        "    return ' '.join([ps.stem(word) for word in words])\n",
        "\n",
        "# (6) Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def apply_lemmatization(text):\n",
        "    words = text.split()\n",
        "    return ' '.join([lemmatizer.lemmatize(word) for word in words])\n",
        "\n",
        "# Apply the cleaning steps to each review\n",
        "def clean_text(text):\n",
        "    text = remove_special_characters(text)  # Step 1\n",
        "    text = remove_numbers(text)             # Step 2\n",
        "    text = remove_stopwords(text)           # Step 3\n",
        "    text = convert_to_lowercase(text)       # Step 4\n",
        "    stemmed_text = apply_stemming(text)     # Step 5 (stemming)\n",
        "    lemmatized_text = apply_lemmatization(text)  # Step 6 (lemmatization)\n",
        "    return stemmed_text, lemmatized_text\n",
        "\n",
        "# Create new columns for cleaned text\n",
        "df['Stemmed_Content'], df['Lemmatized_Content'] = zip(*df['Content'].map(clean_text))\n",
        "\n",
        "# Save the cleaned data back to a new CSV file\n",
        "df.to_csv('imdb_reviews_cleaned.csv', index=False)\n",
        "print(\"Cleaned data saved to 'imdb_reviews_cleaned.csv'.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F_PZdH9Sh49"
      },
      "source": [
        "# Question 3 (30 points)\n",
        "\n",
        "Write a python program to **conduct syntax and structure analysis of the clean text** you just saved above. The syntax and structure analysis includes:\n",
        "\n",
        "(1) **Parts of Speech (POS) Tagging:** Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) **Constituency Parsing and Dependency Parsing:** print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) **Named Entity Recognition:** Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Y0oOSlsOS0cq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b72f8ac0-f4ee-422b-c3f3-4b8017c0a799"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: get flashok live positive buzz early screening nowhere near one good comic book movie time even conversation one good dc movie lot fun ita lot may depend feeling ezra miller younger barry allen really annoying think that s point issue rolethe stand michael keaton batman thing danny elfman iconic score boom joy make mistake batman flash movie feature keaton batmansupergirl good enjoy get stand alone\n",
            "Dependency Parsing:\n",
            "Constituency Parsing: \n",
            "Sentence: i d watch surprise I m amazed leakedit feel run time time cgi dodgy especially certain moment consider go can not believe release like cgi moment big complaintthey get away lot rating include nudity fair amount bad language include f bombim sure ill watch good time watch one time\n",
            "Dependency Parsing:\n",
            "Constituency Parsing: \n",
            "Entity Counts: Counter({'PERSON': 3425, 'CARDINAL': 2929, 'NORP': 990, 'ORG': 927, 'DATE': 876, 'ORDINAL': 828, 'GPE': 598, 'TIME': 389, 'EVENT': 45, 'QUANTITY': 42, 'PRODUCT': 32, 'FAC': 31, 'LANGUAGE': 28, 'LAW': 27, 'LOC': 23, 'PERCENT': 9, 'MONEY': 2})\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "\n",
        "# Import necessary libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from spacy import displacy\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the spaCy model for English\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Text cleaning function\n",
        "def clean_text(text):\n",
        "    # (1) Remove special characters and punctuations\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # (2) Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # (3) Remove stopwords\n",
        "    text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "    # (4) Lowercase the text\n",
        "    text = text.lower()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Stemming (using nltk's Porter Stemmer)\n",
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def stem_text(text):\n",
        "    return ' '.join([stemmer.stem(word) for word in text.split()])\n",
        "\n",
        "# Lemmatization (using spaCy's built-in lemmatizer)\n",
        "def lemmatize_text(text):\n",
        "    doc = nlp(text)\n",
        "    return ' '.join([token.lemma_ for token in doc])\n",
        "\n",
        "# Load the collected reviews\n",
        "df = pd.read_csv('imdb_reviews.csv')\n",
        "\n",
        "# Clean the 'Content' column and save in a new column\n",
        "df['Cleaned_Content'] = df['Content'].apply(clean_text)\n",
        "\n",
        "# Apply stemming and save in a new column\n",
        "df['Stemmed_Content'] = df['Cleaned_Content'].apply(stem_text)\n",
        "\n",
        "# Apply lemmatization and save in a new column\n",
        "df['Lemmatized_Content'] = df['Cleaned_Content'].apply(lemmatize_text)\n",
        "\n",
        "# Save the cleaned, stemmed, and lemmatized data to a new CSV\n",
        "df.to_csv('imdb_reviews_cleaned.csv', index=False)\n",
        "\n",
        "# (1) POS Tagging: Counting Nouns, Verbs, Adjectives, and Adverbs\n",
        "def pos_tagging(text):\n",
        "    doc = nlp(text)\n",
        "    pos_counts = Counter([token.pos_ for token in doc])\n",
        "    return pos_counts['NOUN'], pos_counts['VERB'], pos_counts['ADJ'], pos_counts['ADV']\n",
        "\n",
        "df['Nouns'], df['Verbs'], df['Adjectives'], df['Adverbs'] = zip(*df['Lemmatized_Content'].apply(pos_tagging))\n",
        "\n",
        "# Save the dataframe with POS tags\n",
        "df.to_csv('imdb_reviews_with_pos.csv', index=False)\n",
        "\n",
        "# (2) Constituency Parsing and Dependency Parsing (Example sentence parsing)\n",
        "def parse_and_visualize(text):\n",
        "    doc = nlp(text)\n",
        "    for sent in doc.sents:\n",
        "        print(f\"Sentence: {sent.text}\")\n",
        "        print(\"Dependency Parsing:\")\n",
        "        displacy.render(sent, style=\"dep\", jupyter=False)  # Dependency parsing\n",
        "        print(\"Constituency Parsing: \")\n",
        "        displacy.render(doc, style=\"dep\", jupyter=False)  # Constituency parsing\n",
        "\n",
        "# Example: Parse and visualize the first review\n",
        "first_review = df['Lemmatized_Content'].iloc[0]\n",
        "parse_and_visualize(first_review)\n",
        "\n",
        "# (3) Named Entity Recognition (NER): Extract and count entities\n",
        "def perform_ner(text):\n",
        "    doc = nlp(text)\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return entities\n",
        "\n",
        "df['Entities'] = df['Lemmatized_Content'].apply(perform_ner)\n",
        "\n",
        "# Count entity types\n",
        "entity_counter = Counter([entity[1] for sublist in df['Entities'] for entity in sublist])\n",
        "print(\"Entity Counts:\", entity_counter)\n",
        "\n",
        "# Save the dataframe with NER data\n",
        "df.to_csv('imdb_reviews_with_ner.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Comment**\n",
        "Make sure to submit the cleaned data CSV in the comment section - 10 points"
      ],
      "metadata": {
        "id": "CXNn1lEVbMsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download each CSV file\n",
        "files.download('imdb_reviews.csv')  # Original reviews\n",
        "files.download('imdb_reviews_cleaned.csv')  # Cleaned reviews\n",
        "files.download('imdb_reviews_with_pos.csv')  # Reviews with POS tagging\n",
        "files.download('imdb_reviews_with_ner.csv')  # Reviews with NER\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "JaiPOQnpSmjR",
        "outputId": "c3058f56-1bbc-4991-abf5-be75c5d75378"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_71b621d3-e68b-45ed-8297-bffdde0727f1\", \"imdb_reviews.csv\", 2532428)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c63bd22b-0642-4db5-bfa2-d6ac83648a2d\", \"imdb_reviews_cleaned.csv\", 7120988)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5d516b84-983d-4788-8bb8-fbd7f62c2144\", \"imdb_reviews_with_pos.csv\", 7137195)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3ede2773-fa55-446b-8802-37fc099317ea\", \"imdb_reviews_with_ner.csv\", 7414132)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question\n",
        "\n",
        "Provide your thoughts on the assignment. What did you find challenging, and what aspects did you enjoy? Your opinion on the provided time to complete the assignment."
      ],
      "metadata": {
        "id": "q8BFCvWp32cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your response below\n",
        "'''\n",
        "\n",
        "Obstacles\n",
        "\n",
        "Information Gathering: Because of possible blocks and shifting page layouts, it was challenging to extract information from IMDb.\n",
        "Data Cleaning: Using text cleaning techniques like lemmatization and stemming required a thorough grasp of natural language processing.\n",
        "Techniques for Analysis: It took a while to understand syntax and structural analysis, which included parsing and POS tagging.\n",
        "Satisfying Features:\n",
        "\n",
        "Opportunities for Learning: It was satisfying to have some practical experience with Python packages like pandas and nltk.\n",
        "Data insights were obtained using NER analysis of cleansed data, which was a pleasant process.\n",
        "Solving problems: It was interesting and instructive to overcome scraping and analyzing obstacles.\n",
        "Organizing Your Time:\n",
        "\n",
        "While much of the time allotted was fair, it might have been more, particularly for people who were not as experienced with the techniques.\n",
        "All in all, the task offered a thorough and fulfilling education in data analysis expertise.\n",
        "'''"
      ],
      "metadata": {
        "id": "_e557s2w4BpK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "e3883970-dd2d-437d-b851-12647f425c87"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nObstacles\\n\\nInformation Gathering: Because of possible blocks and shifting page layouts, it was challenging to extract information from IMDb.\\nData Cleaning: Using text cleaning techniques like lemmatization and stemming required a thorough grasp of natural language processing.\\nTechniques for Analysis: It took a while to understand syntax and structural analysis, which included parsing and POS tagging.\\nSatisfying Features:\\n\\nOpportunities for Learning: It was satisfying to have some practical experience with Python packages like pandas and nltk.\\nData insights were obtained using NER analysis of cleansed data, which was a pleasant process.\\nSolving problems: It was interesting and instructive to overcome scraping and analyzing obstacles.\\nOrganizing Your Time:\\n\\nWhile much of the time allotted was fair, it might have been more, particularly for people who were not as experienced with the techniques.\\nAll in all, the task offered a thorough and fulfilling education in data analysis expertise.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OP4-5qxAtInv"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}