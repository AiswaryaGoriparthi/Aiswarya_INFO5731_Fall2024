{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "from time import sleep\n",
        "\n",
        "# Dataset URLs\n",
        "datasets = {\n",
        "    \"City\": {\n",
        "        \"main\": \"https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_09_26_drive_0001/2011_09_26_drive_0001_sync.zip\",\n",
        "        \"tracklets\": \"https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_09_26_drive_0001/2011_09_26_drive_0001_tracklets.zip\",\n",
        "        \"calib\": \"https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_09_26_calib.zip\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Base directory\n",
        "base_dir = \"./kitti_online\"\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Download function with retries\n",
        "def download_file(url, save_path, retries=3):\n",
        "    \"\"\"Download a file with retry logic.\"\"\"\n",
        "    attempt = 0\n",
        "    while attempt < retries:\n",
        "        print(f\"Attempting to download {url} (Attempt {attempt + 1}/{retries})...\")\n",
        "        response = requests.get(url, stream=True)\n",
        "        if response.status_code == 200:\n",
        "            with open(save_path, \"wb\") as f:\n",
        "                for chunk in response.iter_content(chunk_size=1024):\n",
        "                    if chunk:\n",
        "                        f.write(chunk)\n",
        "            print(f\"Successfully downloaded {url} to {save_path}.\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"Failed to download {url}. HTTP Status: {response.status_code}. Retrying...\")\n",
        "            attempt += 1\n",
        "            sleep(2)\n",
        "    print(f\"Failed to download {url} after {retries} attempts.\")\n",
        "    return False\n",
        "\n",
        "# Function to download and extract dataset components\n",
        "def download_and_extract(url, extract_to, dataset_name, file_type):\n",
        "    \"\"\"Download and extract ZIP files.\"\"\"\n",
        "    print(f\"\\nProcessing {file_type} for {dataset_name}...\")\n",
        "    file_name = url.split('/')[-1]\n",
        "    download_path = os.path.join(extract_to, file_name)\n",
        "\n",
        "    # Download the file if not already downloaded\n",
        "    if not os.path.exists(download_path):\n",
        "        print(f\"Downloading {file_type} for {dataset_name}...\")\n",
        "        if not download_file(url, download_path):\n",
        "            raise Exception(f\"Failed to download {file_type} for {dataset_name}.\")\n",
        "    else:\n",
        "        print(f\"{file_type} for {dataset_name} already downloaded.\")\n",
        "\n",
        "    # Extract the file if not already extracted\n",
        "    if not any(os.path.isdir(os.path.join(extract_to, d)) for d in os.listdir(extract_to)):\n",
        "        print(f\"Extracting {file_type} for {dataset_name}...\")\n",
        "        with zipfile.ZipFile(download_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to)\n",
        "        print(f\"Extracted {file_type} for {dataset_name}.\")\n",
        "    else:\n",
        "        print(f\"{file_type} for {dataset_name} already extracted.\")\n",
        "\n",
        "    return extract_to\n",
        "\n",
        "# Main function to process datasets\n",
        "def main():\n",
        "    for dataset_name, urls in datasets.items():\n",
        "        try:\n",
        "            dataset_dir = os.path.join(base_dir, dataset_name)\n",
        "            os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "            # Download and extract main dataset\n",
        "            download_and_extract(urls[\"main\"], dataset_dir, dataset_name, \"main dataset\")\n",
        "\n",
        "            # Download and extract tracklets\n",
        "            tracklets_dir = os.path.join(dataset_dir, \"tracklets\")\n",
        "            os.makedirs(tracklets_dir, exist_ok=True)\n",
        "            download_and_extract(urls[\"tracklets\"], tracklets_dir, dataset_name, \"tracklets\")\n",
        "\n",
        "            # Download and extract calibration files\n",
        "            calib_dir = os.path.join(dataset_dir, \"calib\")\n",
        "            os.makedirs(calib_dir, exist_ok=True)\n",
        "            download_and_extract(urls[\"calib\"], calib_dir, dataset_name, \"calibration files\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {dataset_name}: {e}\")\n",
        "\n",
        "    print(\"\\nDataset processing completed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTYlR6Ixr96P",
        "outputId": "8aafba13-ec30-4291-a654-732409a81c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing main dataset for City...\n",
            "main dataset for City already downloaded.\n",
            "main dataset for City already extracted.\n",
            "\n",
            "Processing tracklets for City...\n",
            "tracklets for City already downloaded.\n",
            "tracklets for City already extracted.\n",
            "\n",
            "Processing calibration files for City...\n",
            "Downloading calibration files for City...\n",
            "Attempting to download https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_09_26_calib.zip (Attempt 1/3)...\n",
            "Successfully downloaded https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_09_26_calib.zip to ./kitti_online/City/calib/2011_09_26_calib.zip.\n",
            "Extracting calibration files for City...\n",
            "Extracted calibration files for City.\n",
            "\n",
            "Dataset processing completed.\n"
          ]
        }
      ]
    }
  ]
}